# 📱 Telegram 数据处理机器人使用指南

> **为团队内部同事准备的完整使用手册**

## 🚀 快速开始

### 第一步：添加机器人
1. 在 Telegram 中搜索并添加我们的数据处理机器人
2. 发送 `/start` 命令开始使用
3. 系统会自动显示功能菜单，选择您需要的功能

### 第二步：选择功能
- 点击界面上的功能按钮，或直接输入命令
- 随时可以输入 `/menu` 重新显示功能菜单
- 输入 `/help` 查看详细帮助信息

---

## 📋 功能总览

| 功能 | 命令 | 用途 | 输入格式 | 输出格式 |
|------|------|------|----------|----------|
| 📊 日志解析 | `/logparse` | 从日志文件提取结构化数据 | TXT | CSV |
| 🔒 用户锁定 | `/lockuser` | 生成用户锁定命令 | CSV | SQL + Redis命令 |
| 🗄️ SQL解析 | `/sqlparse` | 提取并去重SQL语句 | TXT | 去重SQL文件 |
| ✂️ 文件分割 | `/filesplit` | 将大文件按行数分割 | 任意格式 | 多个小文件 |
| 📋 KYC审核 | `/kycreview` | 处理KYC审核数据 | Excel/CSV | SQL更新语句 |
| 🗑️ Redis删除 | `/redisdel` | 生成Redis删除命令 | Excel/CSV | Redis命令文件 |
| ➕ Redis增加 | `/redisadd` | 生成流水设置命令 | CSV | Redis设置命令 |
| 🔄 UID去重 | `/uiddedup` | 去除重复用户ID | CSV | 去重后的CSV |

---

## 🔧 详细功能说明

### 1. 📊 日志解析 (`/logparse`)

**功能说明：** 从应用程序日志中提取关键信息，生成结构化CSV数据

**使用场景：**
- 分析用户行为日志
- 提取支付流水信息
- 追踪请求链路数据

**操作步骤：**
1. 发送 `/logparse` 命令
2. 上传 TXT 格式的日志文件
3. 等待处理完成，下载生成的 CSV 文件

**输入文件要求：**
- 格式：TXT
- 内容：包含结构化日志数据
- 大小：建议不超过 50MB

**输出内容包含：**
- logTime（日志时间）
- userId（用户ID）
- requestUrl（请求URL）
- traceId（追踪ID）
- 其他业务字段

---

### 2. 🔒 用户锁定 (`/lockuser`)

**功能说明：** 批量生成用户账户锁定的SQL和Redis命令

**使用场景：**
- 风控用户批量锁定
- 违规用户处理
- 账户状态批量更新

**操作步骤：**
1. 发送 `/lockuser` 命令
2. 上传包含用户ID的CSV文件（第一列为用户ID）
3. 下载生成的SQL文件和Redis命令文件

**输入文件格式示例：**
```csv
12345
67890
11111
22222
```

**输出文件：**
- `lockUser-db_user库.sql`：用户锁定SQL语句
- `lockUser-redis_db0.txt`：Redis删除命令

---

### 3. 🗄️ SQL解析 (`/sqlparse`)

**功能说明：** 从日志中提取SQL语句并智能去重

**使用场景：**
- 数据库慢查询分析
- SQL语句统计和优化
- 重复查询识别

**操作步骤：**
1. 发送 `/sqlparse` 命令
2. 上传包含SQL的日志文件（TXT格式）
3. 下载去重后的SQL语句文件

**智能去重规则：**
- 基于表名、字段、条件进行去重
- 保留代表性的SQL语句
- 过滤无效和重复的查询

---

### 4. ✂️ 文件分割 (`/filesplit`)

**功能说明：** 将大文件按行数分割成多个小文件

**使用场景：**
- Redis命令文件分割
- 大数据文件处理
- 批量导入数据准备

**操作步骤：**
1. 发送 `/filesplit` 命令
2. 上传需要分割的文件（支持任意格式）
3. 系统自动按10,000行分割
4. 下载压缩包（包含所有分割后的文件）

**分割规则：**
- 每个文件最多10,000行
- 保持原文件格式和扩展名
- 自动生成序号命名

---

### 5. 📋 KYC审核 (`/kycreview`)

**功能说明：** 处理KYC（身份验证）审核通过数据

**使用场景：**
- 用户身份验证状态更新
- KYC审核结果批量处理
- 用户等级状态修改

**操作步骤：**
1. 发送 `/kycreview` 命令
2. 上传KYC数据文件（Excel或CSV格式）
3. 下载生成的SQL更新语句

**输出文件命名：** `kyc-YYYY-MM-DD.sql`

---

### 6. 🗑️ Redis删除命令生成 (`/redisdel`)

**功能说明：** 为用户生成Redis数据删除命令

**使用场景：**
- 用户流水数据清零
- Redis缓存清理
- 数据重置操作

**操作步骤：**
1. 发送 `/redisdel` 命令
2. 上传用户数据文件（Excel或CSV格式）
3. 下载生成的Redis命令文件和执行脚本

**每个用户生成的命令：**
- 删除流水要求数据
- 删除投注流水数据
- 提供批量执行脚本

---

### 7. ➕ Redis流水增加 (`/redisadd`)

**功能说明：** 生成用户流水要求设置命令

**使用场景：**
- 用户流水比例调整
- 投注要求设置
- 活动奖励配置

**CSV文件格式要求：**
| 列位置 | 字段名 | 说明 |
|--------|--------|------|
| 第1列 | 用户ID | 目标用户的唯一标识 |
| 第2列 | 调整金额 | 金额数值 |
| 第3列 | 流水比例 | 流水要求倍数 |
| 第5列 | 投注金额 | 投注相关金额 |

**操作步骤：**
1. 发送 `/redisadd` 命令
2. 按格式准备CSV文件并上传
3. 下载生成的Redis设置命令

---

### 8. 🔄 UID去重 (`/uiddedup`)

**功能说明：** 从用户ID列表中移除重复项

**使用场景：**
- 用户列表清理
- 重复数据检测
- 数据质量验证

**操作步骤：**
1. 发送 `/uiddedup` 命令
2. 上传包含用户ID的CSV文件
3. 下载去重后的文件和详细报告

**输出内容：**
- 去重后的用户ID文件
- 详细去重报告（原始数量、去重后数量、重复数量）

---

## 📝 文件格式要求

### 通用要求
- **文件大小限制：** 50MB
- **支持的格式：** TXT、CSV、XLSX
- **编码要求：** UTF-8
- **文件命名：** 使用英文和数字，避免特殊字符

### CSV文件格式规范
```csv
# 标准CSV格式示例
用户ID,姓名,状态
12345,张三,正常
67890,李四,锁定
```

### Excel文件要求
- 使用 `.xlsx` 格式（不支持 `.xls`）
- 数据从第一行开始，包含表头
- 避免合并单元格和复杂格式

---

## ⚡ 使用技巧

### 1. 提高处理效率
- **批量处理：** 将多个小文件合并后一次处理
- **文件预处理：** 确保数据格式正确，避免处理失败
- **分时处理：** 大文件建议在非高峰时段处理

### 2. 数据准备最佳实践
- 在上传前检查文件格式和数据完整性
- 备份原始文件，避免数据丢失
- 使用有意义的文件名，便于后续管理

### 3. 结果文件处理
- 及时下载处理结果，避免文件过期
- 验证输出数据的正确性
- 在生产环境使用前先在测试环境验证

---

## 🔄 工作流程示例

### 场景：批量锁定违规用户账户

1. **数据收集**
   ```csv
   # 准备用户ID列表 (违规用户.csv)
   用户ID
   12345
   67890
   11111
   ```

2. **机器人处理**
   - 发送 `/lockuser` 命令
   - 上传 `违规用户.csv` 文件
   - 等待处理完成

3. **执行生成的命令**
   - 下载 `lockUser-db_user库.sql`
   - 下载 `lockUser-redis_db0.txt`
   - 在数据库中执行SQL语句
   - 在Redis中执行删除命令

4. **验证结果**
   - 检查用户状态是否已更新
   - 验证Redis数据是否已清理

---

## ❓ 常见问题解答（FAQ）

### Q1：文件上传失败怎么办？
**A：** 检查以下几点：
- 文件大小是否超过50MB限制
- 文件格式是否正确（TXT/CSV/XLSX）
- 网络连接是否稳定
- 重新尝试上传

### Q2：处理时间很长是否正常？
**A：** 处理时间取决于文件大小和复杂度：
- 小文件（<1MB）：通常1-2分钟
- 中等文件（1-10MB）：3-8分钟
- 大文件（10-50MB）：10-30分钟
- 如果超过30分钟无响应，请联系管理员

### Q3：如何确认处理结果正确？
**A：** 建议的验证步骤：
- 检查输出文件的行数是否合理
- 抽样验证几条数据的准确性
- 在测试环境先验证，再在生产环境使用

### Q4：能否同时处理多个文件？
**A：** 目前每次只能处理一个文件，但可以：
- 将多个文件合并后统一处理
- 顺序处理多个文件（处理完一个再处理下一个）

### Q5：处理失败后如何重试？
**A：**
- 输入 `/menu` 重新选择功能
- 检查文件格式后重新上传
- 如果反复失败，请联系技术支持

---

## 🛡️ 安全和注意事项

### 数据安全
- 所有上传的文件会在处理完成后自动清理
- 请勿上传包含敏感个人信息的文件
- 生产数据处理前请在测试环境验证

### 使用规范
- 仅用于授权的数据处理任务
- 不要处理非工作相关的数据
- 遵守公司数据处理政策

### 故障恢复
- 处理过程中如遇到错误，系统会自动清理临时文件
- 用户状态会自动重置，可以重新开始操作
- 如遇到持续问题，请及时联系技术支持

---

## 📞 技术支持

### 联系方式
- **技术支持群：** [内部技术支持群]
- **紧急联系：** [技术负责人联系方式]
- **问题反馈：** [内部问题追踪系统]

### 获取帮助
1. **机器人内置帮助：** 发送 `/help` 查看详细说明
2. **功能菜单：** 随时发送 `/menu` 显示所有功能
3. **技术文档：** 查看项目仓库中的技术文档

---

## 📈 更新日志

### v2.0 (最新版本)
- ✅ 添加了 `/menu` 命令，随时显示功能菜单
- ✅ 处理完成后自动返回菜单，无需手动返回
- ✅ 优化了错误提示和用户体验
- ✅ 增强了文件上传失败的处理逻辑

### v1.5
- ✅ 新增UID去重功能
- ✅ 优化文件分割性能
- ✅ 增强Redis命令生成功能

### v1.0
- ✅ 基础功能实现
- ✅ 支持8大数据处理功能
- ✅ 完善的错误处理机制

---

## 🎯 最佳实践建议

### 团队协作
1. **统一命名规范：** 使用统一的文件命名格式
2. **结果共享：** 将处理结果保存到团队共享目录
3. **经验分享：** 在团队群中分享使用心得和注意事项

### 效率提升
1. **批量操作：** 尽量将相同类型的任务合并处理
2. **模板准备：** 为常用操作准备标准的文件模板
3. **快捷命令：** 熟记常用命令，提高操作速度

---

**💡 提示：** 这份指南会持续更新，如有建议或发现问题，欢迎及时反馈！

---
*最后更新时间：2025年1月*
*文档版本：v2.0*